{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dca3d0bc",
   "metadata": {},
   "source": [
    "Elastic Net is a regularization technique used in linear regression and other regression-based machine learning models to address some of the limitations of Lasso (L1) and Ridge (L2) regularization methods. It combines both L1 and L2 regularization penalties to strike a balance between them, offering a more robust and flexible regularization approach.\n",
    "\n",
    "In ordinary linear regression, the goal is to minimize the sum of squared residuals (the difference between the predicted values and the actual target values). However, this approach may lead to overfitting, especially when dealing with high-dimensional datasets or when some features are highly correlated.\n",
    "\n",
    "Regularization methods, such as Lasso and Ridge, add penalty terms to the ordinary least squares objective function to prevent overfitting. These penalty terms control the complexity of the model by either shrinking the coefficients of less important features to zero (Lasso) or by reducing their magnitudes (Ridge).\n",
    "\n",
    "Elastic Net combines both L1 and L2 penalties and is defined by the following objective function:\n",
    "\n",
    "\\[\\text{minimize} \\ \\ \\left( \\frac{1}{2n} ||y - X\\beta||_2^2 \\right) + \\lambda_1 ||\\beta||_1 + \\frac{\\lambda_2}{2} ||\\beta||_2^2\\]\n",
    "\n",
    "where:\n",
    "- \\(y\\) is the vector of target values (dependent variable).\n",
    "- \\(X\\) is the matrix of feature values (independent variables).\n",
    "- \\(\\beta\\) is the vector of regression coefficients to be learned.\n",
    "- \\(n\\) is the number of data points in the dataset.\n",
    "- \\(\\lambda_1\\) and \\(\\lambda_2\\) are the regularization hyperparameters that control the strength of L1 and L2 penalties, respectively.\n",
    "\n",
    "Elastic Net provides the benefits of both Lasso and Ridge regularization:\n",
    "\n",
    "1. L1 regularization helps with feature selection by forcing some coefficients to exactly zero. This makes the model more interpretable and can be used for feature selection in high-dimensional datasets.\n",
    "\n",
    "2. L2 regularization helps in dealing with collinearity (high correlation between features) and stabilizes the model by reducing the magnitude of the coefficients.\n",
    "\n",
    "The values of \\(\\lambda_1\\) and \\(\\lambda_2\\) need to be tuned to find the right balance between L1 and L2 regularization, and this can be done using cross-validation.\n",
    "\n",
    "Elastic Net is particularly useful when dealing with datasets containing many features and when some of those features are highly correlated. It provides a more flexible and powerful regularization approach compared to Lasso and Ridge alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfdc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "python\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sample data for demonstration\n",
    "# Replace X and y with your own dataset (features and target variable)\n",
    "# X should be a 2D array-like object where each row represents a sample and each column represents a feature.\n",
    "# y should be a 1D array-like object representing the target variable (labels).\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 5)\n",
    "y = 2 * X[:, 0] + 3 * X[:, 1] - 4 * X[:, 2] + 0.5 * X[:, 3] + np.random.randn(100)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Elastic Net model\n",
    "alpha = 0.1  # Regularization strength (the sum of L1 and L2 regularization penalties)\n",
    "l1_ratio = 0.5  # The mix ratio between L1 and L2 regularization (0.5 means equal weight to both L1 and L2)\n",
    "elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = elastic_net_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "```\n",
    "\n",
    "# # In this code, we use synthetic data for demonstration purposes, but you should replace `X` and `y`\n",
    "# with your own dataset. The Elastic Net model is created using `ElasticNet()` from `sklearn.linear_model`, \n",
    "# and it is trained on the training data using the `fit()` method. The `alpha` parameter controls the \n",
    "# regularization strength (higher values mean stronger regularization), and the `l1_ratio` parameter \n",
    "# determines the mix between L1 and L2 regularization (0.5 means equal weight to both penalties).\n",
    "\n",
    "# # The model is then used to make predictions on the test set, and the performance is evaluated using \n",
    "# Mean Squared Error (MSE) and R-squared (R2) metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
