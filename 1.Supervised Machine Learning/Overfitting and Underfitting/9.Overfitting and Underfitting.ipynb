{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7b46d7",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2da7ab3e",
   "metadata": {},
   "source": [
    "Bias:\n",
    "    It is only about the training data, when we discuss about overfitting and underfitting concepts or issue.\n",
    "    If bias is very low, then training data accuracy is high >> 90-95%\n",
    "    If bias is high, then training data accuracy is low >>  70-80%\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba4dde",
   "metadata": {},
   "source": [
    "## Varience"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eacba3bc",
   "metadata": {},
   "source": [
    "Varience:\n",
    "    It is difference between the accuracies of two different training and testing datasets.\n",
    "    \n",
    "High Varience : High difference in between accuracies of training and testing datasets.\n",
    "    \n",
    "Low Varience: Low/less difference in between accuracies of training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dde644",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bd84c26",
   "metadata": {},
   "source": [
    "Overfitting occurs when our ML model tries to cover all the data points or more than required data points from the dataset.\n",
    "Training data accuracy >> 95%\n",
    "Testing data accuracy  >> 70%\n",
    "\n",
    "Model does perform well only on training dataset.\n",
    "There is a lot difference in between training and testing data accuracy.\n",
    "Low Bias and High Varience.\n",
    "\n",
    "Training data accuracy >> 95%(Regression), >> 97%(Classification)\n",
    "Testing data accuracy  >> 70%(Regression), >> 70-75%(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e8c95",
   "metadata": {},
   "source": [
    "# Underfitting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbaba794",
   "metadata": {},
   "source": [
    "It occurs when our model is not able to cover/capture the trend of data.\n",
    "\n",
    "Training data accuracy >> 75%\n",
    "Testing data accuracy >> 70%\n",
    "\n",
    "Model is neither perform well on training dataset nor on testing dataset.\n",
    "High Bias and Low Varience\n",
    "\n",
    "Training data accuracy >> 55%(Regression), >> 70%(Classification)\n",
    "Testing data accuracy  >> 52%(Regression), >> 68%(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d5066",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fcdf5e1",
   "metadata": {},
   "source": [
    "Model is performing well on training dataset as well as testing dataset.\n",
    "\n",
    "Training data accuracy >> 95%(Regression), >> 97%(Classification)\n",
    "Testing data accuracy  >> 92%(Regression), >> 95%(Classification)\n",
    "\n",
    "Low Bias and Low Varience"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd02c837",
   "metadata": {},
   "source": [
    "Low Bias and High Varience >> Overfitting\n",
    "High Bias and Low Varience >> Underffiting\n",
    "Low Bias and Low Varience  >> Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d937c1",
   "metadata": {},
   "source": [
    "## Different Conditions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd1c7b67",
   "metadata": {},
   "source": [
    "1. High training data accuracy and low testing data accuracy >> Overfitting\n",
    "   Low Bias and High Varience\n",
    "\n",
    "2. Low Training data accuracy and High testing data Accuracy >> Practically not possible.\n",
    "\n",
    "3. Low training data accuracy and low testing data accuracy >> Underfitting\n",
    "   High Bias and Low Varience \n",
    "\n",
    "4. High training data accuracy and High testing data accuracy >> Best Model\n",
    "   Low Bias and Low Varience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b9d1a",
   "metadata": {},
   "source": [
    "# How to Handle/Avoid Overfitting issue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68724c23",
   "metadata": {},
   "source": [
    "1. Hyperparameter Tunning:\n",
    "   Parameters which define the model architecture are referred to as hyper parameter. And the process of searching the best parameters for ideal model or best model building is nothing but Hyper-parameter tunning.\n",
    "   a. GridSearchCV\n",
    "   b. RandomizedSearchCV\n",
    "   \n",
    "2. Train with more data (no. of observations(no. of rows) should be as much as possible.)\n",
    "\n",
    "3. Reduce No. of features(30 >> 15, features/variables)\n",
    "   1.Feature Selection Techniques >> \n",
    "     1. Statistical method\n",
    "     2. wrapper method\n",
    "     3. Embedded method\n",
    "     4. Filter method.\n",
    "   \n",
    "   2.Dimensionality Reduction Technique( PCA, LDA ) LDA >> Linear Density Analysis,Principle Component Analysis.\n",
    "   \n",
    "4. Prunning( Cutting Branches of the Decision Tree) >> Tree Based Model\n",
    "\n",
    "5. Regularization(L1 and L2) : Only used in linear Model (Linear Regression and Logistic Regression)\n",
    "   a. L1 Regularization >> Lasso Regression\n",
    "   b. L2 Regularization >> Ridge Regression\n",
    "   \n",
    "6. Cross Validation:\n",
    "    K-fold cross validation\n",
    "    \n",
    "7. Remove Outliers >> The datapoints which are far away from other datapoints those datapoints we can called outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c409d56",
   "metadata": {},
   "source": [
    "# How to Handle/Avoid Underfitting issue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b264ea9d",
   "metadata": {},
   "source": [
    "1. Increase the no. of features\n",
    "   10 >> 15 ( adding new variables)\n",
    "   add derived features(creating multiple features from single feature.)\n",
    "    \n",
    "2. use Proper Feature Selection: (Both using overfitting and underfitting)\n",
    "    1. Filter Method\n",
    "    2. Wrapper Method\n",
    "    3. Embedded Method\n",
    "    \n",
    "3. Hyper-parameter Tunning it is used for both underfitting and overfitting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "927e8f36",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier( criterion=['gini','entropy']\n",
    "                        max_depth=None,\n",
    "                        min_samples_split=(2,20),\n",
    "                        min_samples_leaf=(1,5))\n",
    "\n",
    "1. ID3 >> Iterative Decomiser 3 >> Entropy\n",
    "2. CART >> Classification and Regression Tree >> gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366fd07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
