{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84436ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61eb6f33",
   "metadata": {},
   "source": [
    "PDF :\n",
    "1. pdftotext\n",
    "2. pyPDF2\n",
    "3. tabula-py (tabular data)\n",
    "4. camelot(tabular data)\n",
    "\n",
    "Image:\n",
    "1. Pytesseract\n",
    "2. Google vision\n",
    "3. Amezon Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79017ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\jupyter notebook\\\\12.Data Science And Machine Learning\\\\1.Supervised Machine Learning\\\\7.Naive Bayes'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ebd3284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path='C:\\\\Users\\\\Admin\\\\Downloads\\\\movie_reviews\\\\'\n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b249476",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_folder_path='C:\\\\Users\\\\Admin\\\\Downloads\\\\movie_reviews\\\\' + 'positive'\n",
    "neg_folder_path='C:\\\\Users\\\\Admin\\\\Downloads\\\\movie_reviews\\\\' + 'negative'\n",
    "\n",
    "pos_text_files=glob.glob(f'{pos_folder_path}\\\\*.txt')\n",
    "neg_text_files=glob.glob(f'{neg_folder_path}\\\\*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39bef15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f54948d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ddea897",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = []\n",
    "\n",
    "for file_name in pos_text_files:\n",
    "    f = open(file_name)\n",
    "    text = f.read()\n",
    "    text = re.sub('[^a-zA-Z]+', ' ', text)\n",
    "    f.close()\n",
    "#     print(text)\n",
    "    review_list.append(text)\n",
    "    \n",
    "for file_name in neg_text_files:\n",
    "    f = open(file_name)\n",
    "    text = f.read()\n",
    "    text = re.sub('[^a-zA-Z]+', ' ', text)\n",
    "    f.close()\n",
    "    review_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2721ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6795dd5",
   "metadata": {},
   "source": [
    "## create Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0161fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1995    0\n",
       "1996    0\n",
       "1997    0\n",
       "1998    0\n",
       "1999    0\n",
       "Length: 2000, dtype: int32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_target=np.ones(len(pos_text_files),dtype=int)\n",
    "neg_target=np.zeros(len(neg_text_files),dtype=int)\n",
    "\n",
    "y=np.append(pos_target,neg_target)\n",
    "y=pd.Series(y) # if we do not want as an array and as an list if we want simple output we do it series\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b01e07",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b8c737a",
   "metadata": {},
   "source": [
    "text1 = 'python is a user friendly language'\n",
    "text2 = 'python is a dynamically typed language'\n",
    "\n",
    "        python is  user friendly language dynamically typed\n",
    "text1     1     1   1      1        1          0        0\n",
    "text2     1     1   0      0        1          1        1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a6a6a5",
   "metadata": {},
   "source": [
    "## Stemming And Lemmetization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ef495ed",
   "metadata": {},
   "source": [
    "classify, \n",
    "classification, \n",
    "classifying\n",
    "\n",
    "history\n",
    "historical\n",
    "\n",
    "good\n",
    "better\n",
    "best\n",
    "\n",
    "stemming >> classif, histor\n",
    "lemmetization>> clasify, history, good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6372f",
   "metadata": {},
   "source": [
    "## min_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "280568f2",
   "metadata": {},
   "source": [
    "min_df = 0.05 >> it ignores terms/features that appears in less than 5% documents\n",
    "min_df = 0.1  >> it ignores terms/features that appears in less than 10% documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f99d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AKSHAY\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  absolutely  act  acting  action  actor  actors  actress  \\\n",
       "0           0     0           0    0       1       0      0       0        0   \n",
       "1           0     0           0    0       0       0      0       0        0   \n",
       "2           0     0           1    0       1       0      0       0        0   \n",
       "3           0     0           0    5       1       0      0       1        0   \n",
       "4           0     0           0    0       0       0      0       1        0   \n",
       "...       ...   ...         ...  ...     ...     ...    ...     ...      ...   \n",
       "1995        0     0           1    0       0       0      0       0        0   \n",
       "1996        1     0           0    0       0       0      0       0        0   \n",
       "1997        1     0           0    1       0       0      1       0        0   \n",
       "1998        0     0           0    0       0       0      1       0        0   \n",
       "1999        0     0           0    0       0       0      0       0        0   \n",
       "\n",
       "      actual  ...  writers  writing  written  wrong  wrote  year  years  yes  \\\n",
       "0          0  ...        0        0        0      0      0     0      0    0   \n",
       "1          0  ...        0        0        0      0      0     1      0    0   \n",
       "2          0  ...        0        0        0      0      0     2      0    0   \n",
       "3          1  ...        0        0        0      0      0     0      1    0   \n",
       "4          0  ...        0        0        0      0      0     0      0    0   \n",
       "...      ...  ...      ...      ...      ...    ...    ...   ...    ...  ...   \n",
       "1995       0  ...        0        0        0      0      0     2      0    1   \n",
       "1996       0  ...        0        0        0      0      0     1      1    0   \n",
       "1997       0  ...        0        0        0      0      0     0      0    0   \n",
       "1998       0  ...        0        0        1      1      0     0      0    0   \n",
       "1999       0  ...        0        0        0      0      0     0      0    0   \n",
       "\n",
       "      york  young  \n",
       "0        0      0  \n",
       "1        0      0  \n",
       "2        0      0  \n",
       "3        1      1  \n",
       "4        1      0  \n",
       "...    ...    ...  \n",
       "1995     0      0  \n",
       "1996     0      0  \n",
       "1997     0      0  \n",
       "1998     0      0  \n",
       "1999     0      0  \n",
       "\n",
       "[2000 rows x 886 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector=CountVectorizer(stop_words='english',min_df=0.05)\n",
    "x_cnt_vector=count_vector.fit_transform(review_list)\n",
    "x=pd.DataFrame(x_cnt_vector.toarray(),columns=count_vector.get_feature_names())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c28d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolutely', 'act', 'acting', 'action', 'actor', 'actors', 'actress', 'actual', 'actually', 'add', 'adds', 'admit', 'age', 'agent', 'ago', 'air', 'alien', 'alive', 'amazing', 'america', 'american', 'amusing', 'annoying', 'apart', 'apparently', 'appear', 'appearance', 'appears', 'approach', 'aren', 'art', 'aside', 'ask', 'asks', 'aspect', 'atmosphere', 'attempt', 'attempts', 'attention', 'audience', 'audiences', 'average', 'away', 'awful', 'baby', 'background', 'bad', 'based', 'basic', 'basically', 'battle', 'beautiful', 'begin', 'beginning', 'begins', 'believable', 'believe', 'ben', 'best', 'better', 'big', 'biggest', 'bit', 'black', 'blood', 'blue', 'body', 'book', 'boring', 'box', 'boy', 'break', 'brief', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'bruce', 'budget', 'building', 'bunch', 'business', 'called', 'came', 'camera', 'car', 'care', 'career', 'case', 'cast', 'casting', 'caught', 'central', 'century', 'certain', 'certainly', 'chance', 'change', 'changes', 'character', 'characters', 'charm', 'chase', 'cheap', 'chemistry', 'child', 'children', 'choice', 'chris', 'cinema', 'cinematic', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clever', 'climax', 'close', 'cold', 'college', 'come', 'comedy', 'comes', 'comic', 'coming', 'common', 'company', 'complete', 'completely', 'complex', 'computer', 'conclusion', 'consider', 'considering', 'constantly', 'contains', 'control', 'convincing', 'cool', 'cop', 'couldn', 'country', 'couple', 'course', 'create', 'created', 'credit', 'credits', 'crew', 'crime', 'critics', 'cut', 'cute', 'dark', 'date', 'daughter', 'david', 'day', 'days', 'dead', 'deal', 'death', 'decent', 'decide', 'decides', 'deep', 'definitely', 'delivers', 'depth', 'deserves', 'despite', 'details', 'development', 'dialogue', 'did', 'didn', 'die', 'different', 'difficult', 'directed', 'directing', 'direction', 'director', 'discovers', 'does', 'doesn', 'dog', 'doing', 'don', 'double', 'doubt', 'dr', 'drama', 'dramatic', 'dream', 'dull', 'dumb', 'earlier', 'early', 'earth', 'easily', 'easy', 'effect', 'effective', 'effects', 'effort', 'element', 'elements', 'emotional', 'end', 'ending', 'ends', 'energy', 'english', 'enjoy', 'enjoyable', 'entertaining', 'entertainment', 'entire', 'entirely', 'equally', 'escape', 'especially', 'events', 'eventually', 'evil', 'ex', 'exactly', 'example', 'excellent', 'exciting', 'expect', 'expected', 'experience', 'extremely', 'eye', 'eyes', 'face', 'fact', 'fails', 'fairly', 'fall', 'falls', 'familiar', 'family', 'famous', 'fan', 'fans', 'far', 'fast', 'father', 'favorite', 'fear', 'feature', 'features', 'feel', 'feeling', 'feels', 'fellow', 'felt', 'female', 'fiction', 'fight', 'figure', 'filled', 'film', 'filmmakers', 'films', 'final', 'finally', 'finds', 'fine', 'flat', 'flaws', 'flick', 'focus', 'follow', 'following', 'follows', 'force', 'forced', 'forget', 'form', 'free', 'friend', 'friends', 'fun', 'funny', 'future', 'game', 'gave', 'general', 'genre', 'george', 'gets', 'getting', 'giant', 'girl', 'girlfriend', 'girls', 'given', 'gives', 'giving', 'god', 'goes', 'going', 'gone', 'good', 'got', 'great', 'greatest', 'ground', 'group', 'guess', 'gun', 'guy', 'guys', 'half', 'hand', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardly', 'hate', 'haven', 'having', 'head', 'hear', 'heard', 'heart', 'heavy', 'hell', 'help', 'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold', 'hollywood', 'home', 'hope', 'horror', 'hot', 'hour', 'hours', 'house', 'huge', 'human', 'humor', 'husband', 'idea', 'ideas', 'imagine', 'immediately', 'important', 'impossible', 'impressive', 'include', 'includes', 'including', 'incredibly', 'inside', 'instead', 'intelligence', 'intelligent', 'interested', 'interesting', 'introduced', 'involved', 'involving', 'isn', 'jack', 'james', 'jim', 'job', 'joe', 'john', 'joke', 'jokes', 'jones', 'just', 'keeps', 'kevin', 'key', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew', 'know', 'known', 'knows', 'lack', 'language', 'large', 'late', 'later', 'latest', 'laugh', 'laughs', 'law', 'lead', 'leading', 'leads', 'learn', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'let', 'level', 'lies', 'life', 'light', 'like', 'liked', 'likely', 'line', 'lines', 'list', 'literally', 'little', 'live', 'lives', 'living', 'll', 'local', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'loud', 'love', 'low', 'main', 'major', 'make', 'makes', 'making', 'man', 'manages', 'manner', 'mark', 'married', 'martin', 'material', 'matter', 'maybe', 'mean', 'means', 'meet', 'meets', 'member', 'members', 'memorable', 'men', 'mention', 'merely', 'mess', 'message', 'michael', 'middle', 'million', 'mind', 'minor', 'minute', 'minutes', 'miss', 'missing', 'mission', 'modern', 'moment', 'moments', 'money', 'mother', 'motion', 'moves', 'movie', 'movies', 'moving', 'mr', 'murder', 'music', 'musical', 'mysterious', 'mystery', 'named', 'nature', 'near', 'nearly', 'need', 'needed', 'needs', 'new', 'nice', 'night', 'non', 'note', 'novel', 'number', 'obvious', 'obviously', 'occasionally', 'offers', 'office', 'oh', 'okay', 'old', 'ones', 'open', 'opening', 'opens', 'opportunity', 'order', 'original', 'oscar', 'outside', 'overall', 'pace', 'parents', 'particular', 'particularly', 'parts', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'person', 'personal', 'peter', 'picture', 'pictures', 'piece', 'place', 'plan', 'planet', 'play', 'played', 'playing', 'plays', 'plenty', 'plot', 'point', 'points', 'police', 'poor', 'popular', 'possible', 'possibly', 'potential', 'power', 'powerful', 'predictable', 'premise', 'presence', 'present', 'pretty', 'previous', 'prison', 'private', 'probably', 'problem', 'problems', 'produced', 'producer', 'production', 'project', 'prove', 'proves', 'provide', 'provides', 'pull', 'purpose', 'puts', 'quality', 'question', 'questions', 'quick', 'quickly', 'quite', 'rate', 'rated', 'rating', 'read', 'ready', 'real', 'realistic', 'reality', 'realize', 'really', 'reason', 'reasons', 'recent', 'recently', 'red', 'relationship', 'release', 'released', 'remains', 'remember', 'rest', 'result', 'return', 'review', 'rich', 'richard', 'ride', 'ridiculous', 'right', 'road', 'robert', 'robin', 'rock', 'role', 'roles', 'romance', 'romantic', 'room', 'run', 'running', 'runs', 'said', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'science', 'score', 'scott', 'screen', 'screenplay', 'screenwriter', 'script', 'second', 'secret', 'seeing', 'seemingly', 'seen', 'sees', 'self', 'sense', 'sent', 'sequel', 'sequence', 'sequences', 'series', 'seriously', 'set', 'sets', 'setting', 'sex', 'sexual', 'share', 'ship', 'shoot', 'short', 'shot', 'shots', 'showing', 'shown', 'shows', 'sight', 'silly', 'similar', 'simple', 'simply', 'single', 'sister', 'sit', 'situation', 'situations', 'slightly', 'slow', 'slowly', 'small', 'smart', 'society', 'solid', 'somewhat', 'son', 'song', 'soon', 'sort', 'sound', 'sounds', 'soundtrack', 'space', 'special', 'spend', 'spent', 'stand', 'standard', 'stands', 'star', 'starring', 'stars', 'start', 'starts', 'state', 'stay', 'steve', 'stop', 'store', 'stories', 'story', 'straight', 'strange', 'street', 'strong', 'studio', 'stuff', 'stupid', 'style', 'subject', 'subtle', 'success', 'successful', 'suddenly', 'summer', 'supporting', 'supposed', 'sure', 'surprise', 'surprisingly', 'suspense', 'sweet', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'team', 'teen', 'television', 'tell', 'telling', 'tells', 'tension', 'terrible', 'th', 'thanks', 'theater', 'theme', 'thing', 'things', 'think', 'thinking', 'thinks', 'thought', 'thriller', 'thrown', 'time', 'times', 'title', 'today', 'told', 'tom', 'tone', 'took', 'totally', 'touch', 'tough', 'town', 'tries', 'trip', 'trouble', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'type', 'typical', 'ultimately', 'understand', 'unfortunately', 'unique', 'unlike', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'van', 'various', 've', 'version', 'video', 'view', 'viewer', 'viewers', 'villain', 'violence', 'violent', 'visual', 'voice', 'wait', 'want', 'wanted', 'wants', 'war', 'wasn', 'waste', 'wasted', 'watch', 'watching', 'water', 'way', 'ways', 'went', 'white', 'wife', 'wild', 'william', 'williams', 'win', 'wish', 'woman', 'women', 'won', 'wonder', 'wonderful', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'wouldn', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'year', 'years', 'yes', 'york', 'young']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AKSHAY\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(count_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca076e",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e49ebd6",
   "metadata": {},
   "source": [
    "TF-IDF means Term frequency and Inverse Document frequency\n",
    "TF = (no. of times word present in sentence)/(total no.of words in sentence)\n",
    "IDF = log(no. of sentences/ no. of sentences containing that word)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93d512d0",
   "metadata": {},
   "source": [
    "text1 = 'Data Science is very good field'\n",
    "text2 = 'Data Science is interdisciplinary process'\n",
    "\n",
    "tf = 1/6\n",
    "idf= log(2/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51f75b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AKSHAY\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289285</td>\n",
       "      <td>0.042533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063777</td>\n",
       "      <td>0.043447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043402</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.102257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07528</td>\n",
       "      <td>0.078095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely       act    acting  action     actor  \\\n",
       "0     0.000000   0.0    0.000000  0.000000  0.050373     0.0  0.000000   \n",
       "1     0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "2     0.000000   0.0    0.102356  0.000000  0.068145     0.0  0.000000   \n",
       "3     0.000000   0.0    0.000000  0.289285  0.042533     0.0  0.000000   \n",
       "4     0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "...        ...   ...         ...       ...       ...     ...       ...   \n",
       "1995  0.000000   0.0    0.051310  0.000000  0.000000     0.0  0.000000   \n",
       "1996  0.074700   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "1997  0.102257   0.0    0.000000  0.085858  0.000000     0.0  0.069705   \n",
       "1998  0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.070130   \n",
       "1999  0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "\n",
       "        actors  actress    actual  ...  writers  writing  written     wrong  \\\n",
       "0     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "2     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "3     0.043055      0.0  0.069053  ...      0.0      0.0  0.00000  0.000000   \n",
       "4     0.054598      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "...        ...      ...       ...  ...      ...      ...      ...       ...   \n",
       "1995  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1996  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1997  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1998  0.000000      0.0  0.000000  ...      0.0      0.0  0.07528  0.078095   \n",
       "1999  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "\n",
       "      wrote      year     years       yes      york     young  \n",
       "0       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1       0.0  0.044504  0.000000  0.000000  0.000000  0.000000  \n",
       "2       0.0  0.128293  0.000000  0.000000  0.000000  0.000000  \n",
       "3       0.0  0.000000  0.040127  0.000000  0.063777  0.043447  \n",
       "4       0.0  0.000000  0.000000  0.000000  0.080876  0.000000  \n",
       "...     ...       ...       ...       ...       ...       ...  \n",
       "1995    0.0  0.064312  0.000000  0.047589  0.000000  0.000000  \n",
       "1996    0.0  0.043402  0.043500  0.000000  0.000000  0.000000  \n",
       "1997    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1998    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1999    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2000 rows x 886 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector = TfidfVectorizer(stop_words='english', min_df=0.05)\n",
    "x_tfidf_vector = tfidf_vector.fit_transform(review_list)\n",
    "x = pd.DataFrame(x_tfidf_vector.toarray(), columns=tfidf_vector.get_feature_names())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c115d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c841e48",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89deb2f1",
   "metadata": {},
   "source": [
    "## 1. Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54b782cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_model=GaussianNB()\n",
    "gnb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0fdf8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[164  41]\n",
      " [ 64 131]]\n",
      "Accuracy Score: 0.7375\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       205\n",
      "           1       0.76      0.67      0.71       195\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.74      0.74      0.74       400\n",
      "weighted avg       0.74      0.74      0.74       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=gnb_model.predict(x_test)\n",
    "\n",
    "cnf_martix=confusion_matrix(y_test,y_pred)\n",
    "print('Confusion Matrix:\\n',cnf_martix)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy Score:', acc)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(' Classification Report:\\n', clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc709a",
   "metadata": {},
   "source": [
    "## 2.Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "583bd03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cce49fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix:\n",
      " [[169  36]\n",
      " [ 42 153]]\n",
      "Accuracy Score: 0.805\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       205\n",
      "           1       0.81      0.78      0.80       195\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.81      0.80       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print('Confustion Matrix:\\n', cnf_matrix)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy Score:', acc)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(' Classification Report:\\n', clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827553c2",
   "metadata": {},
   "source": [
    "## Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49673141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba20fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Matrix:\n",
      " [[169  36]\n",
      " [ 51 144]]\n",
      "Accuracy Score: 0.7825\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       205\n",
      "           1       0.80      0.74      0.77       195\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bnb_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print('Confustion Matrix:\\n', cnf_matrix)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy Score:', acc)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(' Classification Report:\\n', clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ab5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model=GaussianNB() # for checking parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
